{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE -- please do NOT put your name(s) in the Python code; instead, name the Python file\n",
    "# itself to include your WPI username(s).\n",
    "\n",
    "# import cv2  # Uncomment if you have OpenCV and want to run the real-time demo\n",
    "import numpy as np\n",
    "\n",
    "def J (w, faces, labels, alpha = 0.):\n",
    "    y_hat=np.dot(faces,w)\n",
    "    dif=y_hat-labels\n",
    "    J=1/2*np.dot(dif.T,dif)+alpha/2*np.dot(w.T,w)\n",
    "    return J  \n",
    "\n",
    "def gradJ (w, faces, labels, alpha = 0.):\n",
    "    dif=np.dot(faces,w)-labels\n",
    "    gradJ=np.dot(faces.T,dif)+alpha*w\n",
    "    return gradJ \n",
    "\n",
    "def gradientDescent (trainingFaces, trainingLabels, testingFaces, testingLabels, alpha = 0.):\n",
    "    w = np.zeros(trainingFaces.shape[1])  # Or set to random vector\n",
    "    J_dif=0.1\n",
    "    Des_gradJ= np.zeros(trainingFaces.shape[1])     \n",
    "    while J_dif > 0.001:\n",
    "        J0=J (w, trainingFaces, trainingLabels,alpha)\n",
    "        Des_gradJ=gradJ (w, trainingFaces, trainingLabels,alpha)\n",
    "        w=w-0.0001*Des_gradJ\n",
    "        J1=J (w, trainingFaces, trainingLabels,alpha)\n",
    "        J_dif=J0-J1\n",
    "    return w\n",
    "\n",
    "def method1 (trainingFaces, trainingLabels, testingFaces, testingLabels):\n",
    "    w = np.zeros(trainingFaces.shape[1]) \n",
    "    mult_faces=np.dot(trainingFaces.T,trainingFaces)\n",
    "    mult_labels=np.dot(trainingFaces.T,trainingLabels)\n",
    "    w=np.linalg.solve(mult_faces,mult_labels)\n",
    "    return w\n",
    "\n",
    "def method2 (trainingFaces, trainingLabels, testingFaces, testingLabels):\n",
    "    return gradientDescent(trainingFaces, trainingLabels, testingFaces, testingLabels)\n",
    "\n",
    "def method3 (trainingFaces, trainingLabels, testingFaces, testingLabels):\n",
    "    alpha = 1e3\n",
    "    return gradientDescent(trainingFaces, trainingLabels, testingFaces, testingLabels, alpha)\n",
    "\n",
    "def reportCosts (w, trainingFaces, trainingLabels, testingFaces, testingLabels, alpha = 0.):\n",
    "    print (\"Training cost: {}\".format(J(w, trainingFaces, trainingLabels, alpha)))\n",
    "    print (\"Testing cost:  {}\".format(J(w, testingFaces, testingLabels, alpha)))\n",
    "\n",
    "# Accesses the web camera, displays a window showing the face, and classifies smiles in real time\n",
    "# Requires OpenCV.\n",
    "def detectSmiles (w):\n",
    "    # Given the image captured from the web camera, classify the smile\n",
    "    def classifySmile (im, imGray, faceBox, w):\n",
    "        # Extract face patch as vector\n",
    "        face = imGray[faceBox[1]:faceBox[1]+faceBox[3], faceBox[0]:faceBox[0]+faceBox[2]]\n",
    "        face = cv2.resize(face, (24, 24))\n",
    "        face = (face - np.mean(face)) / np.std(face)  # Normalize\n",
    "        face = np.reshape(face, face.shape[0]*face.shape[1])\n",
    "\n",
    "        # Classify face patch\n",
    "        yhat = w.dot(face)\n",
    "        print (yhat)\n",
    "\n",
    "        # Draw result as colored rectangle\n",
    "        THICKNESS = 3\n",
    "        green = 128 + (yhat - 0.5) * 255\n",
    "        color = (0, green, 255 - green)\n",
    "        pt1 = (faceBox[0], faceBox[1])\n",
    "        pt2 = (faceBox[0]+faceBox[2], faceBox[1]+faceBox[3])\n",
    "        cv2.rectangle(im, pt1, pt2, color, THICKNESS)\n",
    "\n",
    "    # Starting video capture\n",
    "    vc = cv2.VideoCapture()\n",
    "    vc.open(0)\n",
    "    faceDetector = cv2.CascadeClassifier(\"haarcascade_frontalface_alt2.xml\")  # TODO update the path\n",
    "    while vc.grab():\n",
    "        (tf,im) = vc.read()\n",
    "        im = cv2.resize(im, (im.shape[1]/2, im.shape[0]/2))  # Divide resolution by 2 for speed\n",
    "        imGray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        k = cv2.waitKey(30)\n",
    "        if k >= 0 and chr(k) == 'q':\n",
    "            print (\"quitting\")\n",
    "            break\n",
    "\n",
    "        # Detect faces\n",
    "        faceBoxes = faceDetector.detectMultiScale(imGray)\n",
    "        for faceBox in faceBoxes:\n",
    "            classifySmile(im, imGray, faceBox, w)\n",
    "        cv2.imshow(\"WebCam\", im)\n",
    "\n",
    "    cv2.destroyWindow(\"WebCam\")\n",
    "    vc.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    if ('trainingFaces' not in globals()):  # In ipython, use \"run -i homework2_template.py\" to avoid re-loading of data\n",
    "        trainingFaces = np.load(\"trainingFaces.npy\")\n",
    "        trainingLabels = np.load(\"trainingLabels.npy\")\n",
    "        testingFaces = np.load(\"testingFaces.npy\")\n",
    "        testingLabels = np.load(\"testingLabels.npy\")\n",
    "\n",
    "        A1=np.dot(trainingFaces.T,trainingFaces)\n",
    "        A=A1+0.000001*np.identity(576)\n",
    "        eval,evec = np.linalg.eigh(A)\n",
    "        eval2=np.power(eval,-1/2)\n",
    "        fai=np.diag(eval2)\n",
    "        L=np.dot(evec,fai)\n",
    "        md_trainingFaces=np.dot(trainingFaces,L)\n",
    "        md_testingFaces=np.dot(testingFaces,L)\n",
    "        \n",
    "    w1 = method1(md_trainingFaces, trainingLabels, md_testingFaces, testingLabels)\n",
    "    w2 = method2(md_trainingFaces, trainingLabels, md_testingFaces, testingLabels)\n",
    "    w3 = method3(md_trainingFaces, trainingLabels, md_testingFaces, testingLabels)\n",
    "\n",
    "    for w in [ w1, w2, w3 ]:\n",
    "        reportCosts(w, md_trainingFaces, trainingLabels, md_testingFaces, testingLabels)\n",
    "    \n",
    "    #detectSmiles(w3)  # Requires OpenCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
